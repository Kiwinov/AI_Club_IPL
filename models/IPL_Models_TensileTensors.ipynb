{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5B6Hf1WuU56"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import SelectKBest,chi2,RFECV\n",
        "\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest,chi2,RFECV\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "import joblib\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, KBinsDiscretizer"
      ],
      "metadata": {
        "id": "axO_IzppZ7_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ogUg3pkbZiXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDEt8B9CuacG"
      },
      "outputs": [],
      "source": [
        "# Ignore warnings to see clean output\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45WrnHF2WIGU",
        "outputId": "de8a8dfc-25cd-47f3-d1de-53ed4d2302e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GdcQimYutxu"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df_FP=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI_Club/raw_data/train_data_Total_FP.csv\")\n",
        "df_C=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI_Club/raw_data/train_data_Captain.csv\")\n",
        "df_FPT=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI_Club/raw_data/test_data_Total_FP (1).csv\")\n",
        "df_CT=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AI_Club/raw_data/test_data_Captain (1).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "hxLn0tAEQhwh",
        "outputId": "b767af95-7844-4525-e4a1-bc6f6b283678"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           match_id        season  batting_innings  bowling_innings  \\\n",
              "count  21616.000000  21616.000000     21616.000000     21616.000000   \n",
              "mean   11196.635918   2015.633975         1.497641         1.502359   \n",
              "std     6452.702186      4.663043         0.500006         0.500006   \n",
              "min        1.000000   2008.000000         1.000000         1.000000   \n",
              "25%     5611.750000   2012.000000         1.000000         1.000000   \n",
              "50%    11195.500000   2015.000000         1.000000         2.000000   \n",
              "75%    16783.250000   2020.000000         2.000000         2.000000   \n",
              "max    22362.000000   2023.000000         2.000000         2.000000   \n",
              "\n",
              "       Starting_11     prev_runs    prev_balls    prev_sixes    prev_fours  \\\n",
              "count      21616.0  14699.000000  14699.000000  14699.000000  14699.000000   \n",
              "mean           4.0     19.622559     15.126267      0.759848      1.776720   \n",
              "std            0.0     21.306417     13.636834      1.343462      2.307336   \n",
              "min            4.0      0.000000      0.000000      0.000000      0.000000   \n",
              "25%            4.0      3.000000      5.000000      0.000000      0.000000   \n",
              "50%            4.0     12.000000     11.000000      0.000000      1.000000   \n",
              "75%            4.0     29.000000     22.000000      1.000000      3.000000   \n",
              "max            4.0    175.000000     73.000000     17.000000     19.000000   \n",
              "\n",
              "       prev_wickets  prev_conceded  prev_catches  prev_Dream Team  \\\n",
              "count  11335.000000   11335.000000   6682.000000     20939.000000   \n",
              "mean       0.916542      25.932510      1.022897         0.510292   \n",
              "std        0.998369      10.675894      0.628788         0.499906   \n",
              "min        0.000000       0.000000      0.000000         0.000000   \n",
              "25%        0.000000      18.500000      1.000000         0.000000   \n",
              "50%        1.000000      26.000000      1.000000         1.000000   \n",
              "75%        1.000000      33.000000      1.000000         1.000000   \n",
              "max        6.000000      70.000000      5.000000         1.000000   \n",
              "\n",
              "       prev_Total_FP    prev_overs  prev_fielding_heroics     prev_duck  \\\n",
              "count   20939.000000  11335.000000            6682.000000  21616.000000   \n",
              "mean       39.281389      3.236568               0.275367      0.071521   \n",
              "std        33.193384      1.017250               0.519249      0.257699   \n",
              "min        -4.000000      0.000000               0.000000      0.000000   \n",
              "25%        12.000000      3.000000               0.000000      0.000000   \n",
              "50%        31.000000      4.000000               0.000000      0.000000   \n",
              "75%        57.000000      4.000000               0.000000      0.000000   \n",
              "max       306.000000      4.000000               4.000000      1.000000   \n",
              "\n",
              "               luck      Total_FP  \n",
              "count  21616.000000  21616.000000  \n",
              "mean      49.633142     37.617274  \n",
              "std       28.865971     31.775817  \n",
              "min        0.000000     -4.000000  \n",
              "25%       25.000000     12.000000  \n",
              "50%       50.000000     30.000000  \n",
              "75%       75.000000     55.000000  \n",
              "max       99.000000    306.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-527ce623-200c-41fa-92db-2b00a00ca7ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>match_id</th>\n",
              "      <th>season</th>\n",
              "      <th>batting_innings</th>\n",
              "      <th>bowling_innings</th>\n",
              "      <th>Starting_11</th>\n",
              "      <th>prev_runs</th>\n",
              "      <th>prev_balls</th>\n",
              "      <th>prev_sixes</th>\n",
              "      <th>prev_fours</th>\n",
              "      <th>prev_wickets</th>\n",
              "      <th>prev_conceded</th>\n",
              "      <th>prev_catches</th>\n",
              "      <th>prev_Dream Team</th>\n",
              "      <th>prev_Total_FP</th>\n",
              "      <th>prev_overs</th>\n",
              "      <th>prev_fielding_heroics</th>\n",
              "      <th>prev_duck</th>\n",
              "      <th>luck</th>\n",
              "      <th>Total_FP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>21616.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "      <td>21616.0</td>\n",
              "      <td>14699.000000</td>\n",
              "      <td>14699.000000</td>\n",
              "      <td>14699.000000</td>\n",
              "      <td>14699.000000</td>\n",
              "      <td>11335.000000</td>\n",
              "      <td>11335.000000</td>\n",
              "      <td>6682.000000</td>\n",
              "      <td>20939.000000</td>\n",
              "      <td>20939.000000</td>\n",
              "      <td>11335.000000</td>\n",
              "      <td>6682.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "      <td>21616.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>11196.635918</td>\n",
              "      <td>2015.633975</td>\n",
              "      <td>1.497641</td>\n",
              "      <td>1.502359</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.622559</td>\n",
              "      <td>15.126267</td>\n",
              "      <td>0.759848</td>\n",
              "      <td>1.776720</td>\n",
              "      <td>0.916542</td>\n",
              "      <td>25.932510</td>\n",
              "      <td>1.022897</td>\n",
              "      <td>0.510292</td>\n",
              "      <td>39.281389</td>\n",
              "      <td>3.236568</td>\n",
              "      <td>0.275367</td>\n",
              "      <td>0.071521</td>\n",
              "      <td>49.633142</td>\n",
              "      <td>37.617274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>6452.702186</td>\n",
              "      <td>4.663043</td>\n",
              "      <td>0.500006</td>\n",
              "      <td>0.500006</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.306417</td>\n",
              "      <td>13.636834</td>\n",
              "      <td>1.343462</td>\n",
              "      <td>2.307336</td>\n",
              "      <td>0.998369</td>\n",
              "      <td>10.675894</td>\n",
              "      <td>0.628788</td>\n",
              "      <td>0.499906</td>\n",
              "      <td>33.193384</td>\n",
              "      <td>1.017250</td>\n",
              "      <td>0.519249</td>\n",
              "      <td>0.257699</td>\n",
              "      <td>28.865971</td>\n",
              "      <td>31.775817</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5611.750000</td>\n",
              "      <td>2012.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>12.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11195.500000</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>30.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>16783.250000</td>\n",
              "      <td>2020.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>57.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>55.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>22362.000000</td>\n",
              "      <td>2023.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>306.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>99.000000</td>\n",
              "      <td>306.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-527ce623-200c-41fa-92db-2b00a00ca7ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-527ce623-200c-41fa-92db-2b00a00ca7ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-527ce623-200c-41fa-92db-2b00a00ca7ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2757694d-7f09-403e-811f-f6ffe4b66c02\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2757694d-7f09-403e-811f-f6ffe4b66c02')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2757694d-7f09-403e-811f-f6ffe4b66c02 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_FP\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"match_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7923.676726175879,\n        \"min\": 1.0,\n        \"max\": 22362.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          11196.635917838637,\n          11195.5,\n          21616.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7066.479140830914,\n        \"min\": 4.6630434807106775,\n        \"max\": 21616.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2015.6339748334567,\n          2015.0,\n          21616.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batting_innings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7641.955659298666,\n        \"min\": 0.5000059991527606,\n        \"max\": 21616.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.497640636565507,\n          2.0,\n          0.5000059991527606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bowling_innings\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7641.904916023006,\n        \"min\": 0.5000059991527606,\n        \"max\": 21616.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.502359363434493,\n          2.0,\n          0.5000059991527606\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Starting_11\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7641.198036209467,\n        \"min\": 0.0,\n        \"max\": 21616.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          21616.0,\n          4.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_runs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5184.0671360056585,\n        \"min\": 0.0,\n        \"max\": 14699.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          19.62255935777944,\n          12.0,\n          14699.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_balls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5189.87150228487,\n        \"min\": 0.0,\n        \"max\": 14699.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          15.126267092999523,\n          11.0,\n          14699.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_sixes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5195.869143623754,\n        \"min\": 0.0,\n        \"max\": 14699.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          14699.0,\n          0.7598476086808627,\n          17.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_fours\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5195.517113406138,\n        \"min\": 0.0,\n        \"max\": 14699.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          14699.0,\n          1.7767195047282127,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_wickets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4007.0273635689496,\n        \"min\": 0.0,\n        \"max\": 11335.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          11335.0,\n          0.9165416850463167,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_conceded\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3998.2815311686622,\n        \"min\": 0.0,\n        \"max\": 11335.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          25.93250992501103,\n          26.0,\n          11335.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_catches\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2361.9567601226877,\n        \"min\": 0.0,\n        \"max\": 6682.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          6682.0,\n          1.022897336126908,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_Dream Team\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7402.851911759929,\n        \"min\": 0.0,\n        \"max\": 20939.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.5102917999904485,\n          1.0,\n          0.49990600497246457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_Total_FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7379.752793934511,\n        \"min\": -4.0,\n        \"max\": 20939.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          39.281388796026555,\n          31.0,\n          20939.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_overs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4006.5554949655807,\n        \"min\": 0.0,\n        \"max\": 11335.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          11335.0,\n          3.2365681517423908,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_fielding_heroics\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2362.201986255823,\n        \"min\": 0.0,\n        \"max\": 6682.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2753666566896139,\n          4.0,\n          0.5192486125567752\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prev_duck\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7642.342962954619,\n        \"min\": 0.0,\n        \"max\": 21616.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.07152109548482606,\n          1.0,\n          0.25769924446125897\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"luck\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7625.930009125897,\n        \"min\": 0.0,\n        \"max\": 21616.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          49.63314211695041,\n          50.0,\n          21616.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total_FP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7619.397702903739,\n        \"min\": -4.0,\n        \"max\": 21616.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          37.61727424130274,\n          30.0,\n          21616.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Check the first few rows of the data\n",
        "df_FP.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQHL0mEBRWwx",
        "outputId": "353ec22b-1f4f-4a90-f52d-9751d32456fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['match_id', 'season', 'match_name', 'home_team', 'away_team', 'venue',\n",
              "       'batting_innings', 'bowling_innings', 'Player_name', 'Starting_11',\n",
              "       'bowling_team_bowl', 'batting_team_bat', 'prev_runs', 'prev_balls',\n",
              "       'prev_sixes', 'prev_fours', 'prev_wickets', 'prev_conceded',\n",
              "       'prev_Overs_Bowled', 'prev_catches', 'prev_Dream Team', 'prev_Total_FP',\n",
              "       'prev_overs', 'prev_fielding_heroics', 'prev_duck', 'luck', 'Total_FP'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Check all the columns of the dataframe\n",
        "df_FP.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0usvSB96f_o",
        "outputId": "64421c99-54b6-47b4-9d7a-02fe9a88c00a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20939\n",
            "20939\n"
          ]
        }
      ],
      "source": [
        "# Remove rows with nan values\n",
        "df_FP = df_FP[df_FP[\"prev_Total_FP\"].notna()]\n",
        "df_C = df_C[df_C[\"prev_Total_FP\"].notna()]\n",
        "print(df_C['match_id'].count())\n",
        "print(df_FP['match_id'].count())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EYWJa2eVWp0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khOEE1aaRoSW"
      },
      "outputs": [],
      "source": [
        "# Drop unimportant columns\n",
        "df_FP=df_FP.drop(['Starting_11','match_name','bowling_innings','prev_Overs_Bowled'],axis=1)\n",
        "\n",
        "df_FPT=df_FPT.drop(['Starting_11','match_name','bowling_innings','prev_Overs_Bowled'],axis=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQuWkPRUuxr1"
      },
      "outputs": [],
      "source": [
        "df_C=df_C.drop(['Starting_11'],axis=1)\n",
        "df_CT=df_CT.drop(['Starting_11'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "gmy0bwCfTls0",
        "outputId": "73d17375-9fa7-4bde-c280-07b67c1891d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       match_id  season  home_team  away_team  venue  batting_innings  \\\n",
              "1             2    2008          7          1      7              2.0   \n",
              "2             3    2008          1          0      0              1.0   \n",
              "3             4    2008         12          1     28              1.0   \n",
              "4             5    2008          4          1     11              2.0   \n",
              "5             6    2008         10          1     17              2.0   \n",
              "...         ...     ...        ...        ...    ...              ...   \n",
              "21610     22357    2023          8         12     13              1.0   \n",
              "21611     22358    2023          8         12     13              2.0   \n",
              "21612     22359    2023          7         13     36              2.0   \n",
              "21613     22360    2023         10          3     17              1.0   \n",
              "21614     22361    2023          0          3     18              1.0   \n",
              "\n",
              "       Player_name  bowling_team_bowl  batting_team_bat  prev_runs  ...  \\\n",
              "1                0                 14                 1       26.0  ...   \n",
              "2                0                 14                 1       21.0  ...   \n",
              "3                0                 14                 1        0.0  ...   \n",
              "4                0                 14                 1       20.0  ...   \n",
              "5                0                 14                 1        7.0  ...   \n",
              "...            ...                ...               ...        ...  ...   \n",
              "21610          644                 14                14        NaN  ...   \n",
              "21611          644                 14                14        NaN  ...   \n",
              "21612          644                 14                14        NaN  ...   \n",
              "21613          644                 14                14        NaN  ...   \n",
              "21614          644                 14                14        NaN  ...   \n",
              "\n",
              "       prev_wickets  prev_conceded  prev_catches  prev_Dream Team  \\\n",
              "1               NaN            NaN           NaN              1.0   \n",
              "2               NaN            NaN           1.0              0.0   \n",
              "3               NaN            NaN           2.0              0.0   \n",
              "4               NaN            NaN           0.0              1.0   \n",
              "5               NaN            NaN           0.0              0.0   \n",
              "...             ...            ...           ...              ...   \n",
              "21610           NaN            NaN           NaN              0.0   \n",
              "21611           NaN            NaN           NaN              0.0   \n",
              "21612           NaN            NaN           NaN              0.0   \n",
              "21613           NaN            NaN           NaN              0.0   \n",
              "21614           NaN            NaN           NaN              0.0   \n",
              "\n",
              "       prev_Total_FP  prev_overs  prev_fielding_heroics  prev_duck  luck  \\\n",
              "1               32.0         NaN                    NaN          0    35   \n",
              "2               37.0         NaN                    0.0          0    79   \n",
              "3               18.0         NaN                    0.0          1    33   \n",
              "4               36.0         NaN                    1.0          0    82   \n",
              "5               13.0         NaN                    1.0          0    54   \n",
              "...              ...         ...                    ...        ...   ...   \n",
              "21610           12.0         NaN                    NaN          0    10   \n",
              "21611           20.0         NaN                    NaN          0     3   \n",
              "21612           12.0         NaN                    NaN          0    80   \n",
              "21613           12.0         NaN                    NaN          0     4   \n",
              "21614           20.0         NaN                    NaN          0    57   \n",
              "\n",
              "       Total_FP  \n",
              "1          37.0  \n",
              "2          18.0  \n",
              "3          36.0  \n",
              "4          13.0  \n",
              "5          26.0  \n",
              "...         ...  \n",
              "21610      20.0  \n",
              "21611      12.0  \n",
              "21612      12.0  \n",
              "21613      20.0  \n",
              "21614      16.0  \n",
              "\n",
              "[20939 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-565445e8-fc3d-49b4-bb0a-d5c9473addd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>match_id</th>\n",
              "      <th>season</th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>venue</th>\n",
              "      <th>batting_innings</th>\n",
              "      <th>Player_name</th>\n",
              "      <th>bowling_team_bowl</th>\n",
              "      <th>batting_team_bat</th>\n",
              "      <th>prev_runs</th>\n",
              "      <th>...</th>\n",
              "      <th>prev_wickets</th>\n",
              "      <th>prev_conceded</th>\n",
              "      <th>prev_catches</th>\n",
              "      <th>prev_Dream Team</th>\n",
              "      <th>prev_Total_FP</th>\n",
              "      <th>prev_overs</th>\n",
              "      <th>prev_fielding_heroics</th>\n",
              "      <th>prev_duck</th>\n",
              "      <th>luck</th>\n",
              "      <th>Total_FP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>26.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>37.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>20.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>13.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21610</th>\n",
              "      <td>22357</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>22358</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>2.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21612</th>\n",
              "      <td>22359</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>36</td>\n",
              "      <td>2.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21613</th>\n",
              "      <td>22360</td>\n",
              "      <td>2023</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21614</th>\n",
              "      <td>22361</td>\n",
              "      <td>2023</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20939 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-565445e8-fc3d-49b4-bb0a-d5c9473addd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-565445e8-fc3d-49b4-bb0a-d5c9473addd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-565445e8-fc3d-49b4-bb0a-d5c9473addd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a70249cf-d894-4737-9fd3-8bdade25d29e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a70249cf-d894-4737-9fd3-8bdade25d29e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a70249cf-d894-4737-9fd3-8bdade25d29e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8e362c45-7215-4618-8c4b-7db6b4d37d4f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_FP')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8e362c45-7215-4618-8c4b-7db6b4d37d4f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_FP');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_FP"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Define encoding function\n",
        "def enc(df_FP):\n",
        "  df_FP[\"home_team\"]=label_encoder.fit_transform(df_FP[\"home_team\"])\n",
        "  df_FP[\"batting_team_bat\"]=label_encoder.fit_transform(df_FP[\"batting_team_bat\"])\n",
        "  df_FP[\"bowling_team_bowl\"]=label_encoder.fit_transform(df_FP[\"bowling_team_bowl\"])\n",
        "  df_FP[\"away_team\"]=label_encoder.fit_transform(df_FP[\"away_team\"])\n",
        "  df_FP[\"venue\"]=label_encoder.fit_transform(df_FP[\"venue\"])\n",
        "  df_FP[\"Player_name\"]=label_encoder.fit_transform(df_FP[\"Player_name\"])\n",
        "\n",
        "# Fit and transform the list of teams\n",
        "enc(df_FP)\n",
        "enc(df_FPT)\n",
        "df_C[\"Captain/Vice Captain\"]=label_encoder.fit_transform(df_C[\"Captain/Vice Captain\"])\n",
        "df_FP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qRxrpJhSTlvH",
        "outputId": "6c9b6856-8ef0-4548-a89c-53fbbbaabf43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "balls\n",
            "-1.0     9604\n",
            " 24.0    6330\n",
            " 18.0    2004\n",
            " 12.0    1413\n",
            " 6.0     1006\n",
            " 22.0      80\n",
            " 23.0      73\n",
            " 20.0      57\n",
            " 19.0      56\n",
            " 21.0      54\n",
            " 17.0      34\n",
            " 16.0      34\n",
            " 14.0      32\n",
            " 13.0      31\n",
            " 15.0      29\n",
            " 7.0       17\n",
            " 11.0      17\n",
            " 5.0       12\n",
            " 9.0       11\n",
            " 1.0       10\n",
            " 10.0      10\n",
            " 2.0        8\n",
            " 4.0        7\n",
            " 8.0        6\n",
            " 3.0        3\n",
            " 0.0        1\n",
            "Name: count, dtype: int64\n",
            "economy\n",
            "60.000540    9604\n",
            "6.000000      473\n",
            "6.750000      286\n",
            "6.250000      269\n",
            "7.249999      267\n",
            "             ... \n",
            "5.647059        1\n",
            "4.105264        1\n",
            "16.285700       1\n",
            "7.384614        1\n",
            "11.999997       1\n",
            "Name: count, Length: 494, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Fill nan values and engineer features\n",
        "df_FP[\"prev_overs\"].fillna(-0.1,inplace=True)\n",
        "df_FP[\"balls\"]=6*df_FP[\"prev_overs\"].astype(int)+(df_FP[\"prev_overs\"]-df_FP[\"prev_overs\"].astype(int))*10\n",
        "df_FPT[\"prev_overs\"].fillna(-0.1,inplace=True)\n",
        "df_FPT[\"balls\"]=6*df_FPT[\"prev_overs\"].astype(int)+(df_FPT[\"prev_overs\"]-df_FPT[\"prev_overs\"].astype(int))*10\n",
        "print(df_FP[\"balls\"].value_counts())\n",
        "\n",
        "df_FP[\"prev_conceded\"].fillna(-10, inplace=True)\n",
        "df_FP[\"economy\"] = (df_FP[\"prev_conceded\"] + 1e-5) / (1e-5 + df_FP[\"balls\"]) * 6\n",
        "df_FPT[\"prev_conceded\"].fillna(-10, inplace=True)\n",
        "df_FPT[\"economy\"] = (df_FPT[\"prev_conceded\"] + 1e-5) / (1e-5 + df_FPT[\"balls\"]) * 6\n",
        "print(df_FP[\"economy\"].value_counts())\n",
        "\n",
        "df_FP[\"prev_runs\"].fillna(1.0,inplace=True)\n",
        "df_FP[\"prev_balls\"].fillna(-2.0,inplace=True)\n",
        "df_FPT[\"prev_runs\"].fillna(1.0,inplace=True)\n",
        "df_FPT[\"prev_balls\"].fillna(-2.0,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9a6XKamaWwHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWg8ZEschR9l",
        "outputId": "de993c32-6203-45d8-db75-25fddb819aac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "strikerate\n",
              "-50.000750     6240\n",
              " 100.000000    1446\n",
              " 0.001000       656\n",
              " 50.000250      292\n",
              " 0.000500       291\n",
              "               ... \n",
              " 197.872320       1\n",
              " 128.947361       1\n",
              " 163.999987       1\n",
              " 126.984123       1\n",
              " 165.853642       1\n",
              "Name: count, Length: 2065, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Engineer new features\n",
        "df_FP[\"strikerate\"]=(1e-5+df_FP[\"prev_runs\"])/(df_FP[\"prev_balls\"]+1e-5)*100\n",
        "df_FPT[\"strikerate\"]=(1e-5+df_FPT[\"prev_runs\"])/(df_FPT[\"prev_balls\"]+1e-5)*100\n",
        "print(df_FP[\"strikerate\"].isnull().sum())\n",
        "df_FP[\"strikerate\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unused columns\n",
        "df_FP = df_FP.drop(\n",
        "    [\"prev_overs\", \"prev_conceded\", \"prev_fours\", \"prev_sixes\", \"prev_runs\"], axis=1\n",
        ")\n",
        "df_FPT = df_FPT.drop(\n",
        "    [\"prev_overs\", \"prev_conceded\", \"prev_fours\", \"prev_sixes\", \"prev_runs\"], axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "Ncjb-fGOW6dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrmGz8WGipPG",
        "outputId": "048aa35f-0e89-4d38-cb34-57d376134006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 20939 entries, 1 to 21614\n",
            "Data columns (total 21 columns):\n",
            " #   Column                 Non-Null Count  Dtype  \n",
            "---  ------                 --------------  -----  \n",
            " 0   match_id               20939 non-null  int64  \n",
            " 1   season                 20939 non-null  int64  \n",
            " 2   home_team              20939 non-null  int64  \n",
            " 3   away_team              20939 non-null  int64  \n",
            " 4   venue                  20939 non-null  int64  \n",
            " 5   batting_innings        20939 non-null  float64\n",
            " 6   Player_name            20939 non-null  int64  \n",
            " 7   bowling_team_bowl      20939 non-null  int64  \n",
            " 8   batting_team_bat       20939 non-null  int64  \n",
            " 9   prev_balls             20939 non-null  float64\n",
            " 10  prev_wickets           11335 non-null  float64\n",
            " 11  prev_catches           6682 non-null   float64\n",
            " 12  prev_Dream Team        20939 non-null  float64\n",
            " 13  prev_Total_FP          20939 non-null  float64\n",
            " 14  prev_fielding_heroics  6682 non-null   float64\n",
            " 15  prev_duck              20939 non-null  int64  \n",
            " 16  luck                   20939 non-null  int64  \n",
            " 17  Total_FP               20939 non-null  float64\n",
            " 18  balls                  20939 non-null  float64\n",
            " 19  economy                20939 non-null  float64\n",
            " 20  strikerate             20939 non-null  float64\n",
            "dtypes: float64(11), int64(10)\n",
            "memory usage: 3.5 MB\n"
          ]
        }
      ],
      "source": [
        "# Checking changes\n",
        "df_FP.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5mnae99Tl0Z"
      },
      "outputs": [],
      "source": [
        "# Model performs better by dropping these columns\n",
        "\n",
        "# # Filling nan values again\n",
        "# df_FP[\"prev_fours\"].fillna(-1,inplace=True)\n",
        "# df_FP[\"prev_sixes\"].fillna(-1,inplace=True)\n",
        "# df_FP[\"boundaries\"]=df_FP[\"prev_fours\"]+df_FP[\"prev_sixes\"]\n",
        "# df_FPT[\"prev_fours\"].fillna(-1,inplace=True)\n",
        "# df_FPT[\"prev_sixes\"].fillna(-1,inplace=True)\n",
        "# df_FPT[\"boundaries\"]=df_FPT[\"prev_fours\"]+df_FPT[\"prev_sixes\"]\n",
        "# df_FP[\"boundaries\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcaXr5IlTl2S",
        "outputId": "83358169-d316-40e0-f618-bbb24f5079cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Total_FP\n",
              "-4.0       11\n",
              "-3.0        3\n",
              "-2.0      219\n",
              "-1.0       25\n",
              " 0.0      185\n",
              "         ... \n",
              " 233.0      1\n",
              " 240.0      1\n",
              " 252.0      1\n",
              " 260.0      1\n",
              " 306.0      1\n",
              "Name: count, Length: 207, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Filling nan values again\n",
        "df_FP[\"prev_wickets\"].fillna(-1,inplace=True)\n",
        "df_FP[\"prev_fielding_heroics\"].fillna(0,inplace=True)\n",
        "df_FP[\"prev_catches\"].fillna(0,inplace=True)\n",
        "df_FPT[\"prev_wickets\"].fillna(-1,inplace=True)\n",
        "df_FPT[\"prev_fielding_heroics\"].fillna(0,inplace=True)\n",
        "df_FPT[\"prev_catches\"].fillna(0,inplace=True)\n",
        "df_FP[\"Total_FP\"].value_counts().sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xvVkitCTl6S",
        "outputId": "a2786e81-0c68-45b0-a059-ce4c9872d072"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "(df_FP.isna().sum()).count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "l8UrlEelrG4r",
        "outputId": "35ae5635-89c5-4552-9b5b-0ab032557af6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       match_id  season  home_team  away_team  venue  batting_innings  \\\n",
              "1             2    2008          7          1      7              2.0   \n",
              "2             3    2008          1          0      0              1.0   \n",
              "3             4    2008         12          1     28              1.0   \n",
              "4             5    2008          4          1     11              2.0   \n",
              "5             6    2008         10          1     17              2.0   \n",
              "...         ...     ...        ...        ...    ...              ...   \n",
              "21610     22357    2023          8         12     13              1.0   \n",
              "21611     22358    2023          8         12     13              2.0   \n",
              "21612     22359    2023          7         13     36              2.0   \n",
              "21613     22360    2023         10          3     17              1.0   \n",
              "21614     22361    2023          0          3     18              1.0   \n",
              "\n",
              "       Player_name  bowling_team_bowl  batting_team_bat  prev_balls  ...  \\\n",
              "1                0                 14                 1        21.0  ...   \n",
              "2                0                 14                 1        17.0  ...   \n",
              "3                0                 14                 1         1.0  ...   \n",
              "4                0                 14                 1        22.0  ...   \n",
              "5                0                 14                 1        12.0  ...   \n",
              "...            ...                ...               ...         ...  ...   \n",
              "21610          644                 14                14        -2.0  ...   \n",
              "21611          644                 14                14        -2.0  ...   \n",
              "21612          644                 14                14        -2.0  ...   \n",
              "21613          644                 14                14        -2.0  ...   \n",
              "21614          644                 14                14        -2.0  ...   \n",
              "\n",
              "       prev_catches  prev_Dream Team  prev_Total_FP  prev_fielding_heroics  \\\n",
              "1               0.0              1.0           32.0                    0.0   \n",
              "2               1.0              0.0           37.0                    0.0   \n",
              "3               2.0              0.0           18.0                    0.0   \n",
              "4               0.0              1.0           36.0                    1.0   \n",
              "5               0.0              0.0           13.0                    1.0   \n",
              "...             ...              ...            ...                    ...   \n",
              "21610           0.0              0.0           12.0                    0.0   \n",
              "21611           0.0              0.0           20.0                    0.0   \n",
              "21612           0.0              0.0           12.0                    0.0   \n",
              "21613           0.0              0.0           12.0                    0.0   \n",
              "21614           0.0              0.0           20.0                    0.0   \n",
              "\n",
              "       prev_duck  luck  Total_FP  balls   economy  strikerate  \n",
              "1              0    35      37.0   -1.0  60.00054  123.809512  \n",
              "2              0    79      18.0   -1.0  60.00054  123.529398  \n",
              "3              1    33      36.0   -1.0  60.00054    0.001000  \n",
              "4              0    82      13.0   -1.0  60.00054   90.909095  \n",
              "5              0    54      26.0   -1.0  60.00054   58.333368  \n",
              "...          ...   ...       ...    ...       ...         ...  \n",
              "21610          0    10      20.0   -1.0  60.00054  -50.000750  \n",
              "21611          0     3      12.0   -1.0  60.00054  -50.000750  \n",
              "21612          0    80      12.0   -1.0  60.00054  -50.000750  \n",
              "21613          0     4      20.0   -1.0  60.00054  -50.000750  \n",
              "21614          0    57      16.0   -1.0  60.00054  -50.000750  \n",
              "\n",
              "[20939 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-422a4e33-61c8-4003-9270-98954e98cf01\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>match_id</th>\n",
              "      <th>season</th>\n",
              "      <th>home_team</th>\n",
              "      <th>away_team</th>\n",
              "      <th>venue</th>\n",
              "      <th>batting_innings</th>\n",
              "      <th>Player_name</th>\n",
              "      <th>bowling_team_bowl</th>\n",
              "      <th>batting_team_bat</th>\n",
              "      <th>prev_balls</th>\n",
              "      <th>...</th>\n",
              "      <th>prev_catches</th>\n",
              "      <th>prev_Dream Team</th>\n",
              "      <th>prev_Total_FP</th>\n",
              "      <th>prev_fielding_heroics</th>\n",
              "      <th>prev_duck</th>\n",
              "      <th>luck</th>\n",
              "      <th>Total_FP</th>\n",
              "      <th>balls</th>\n",
              "      <th>economy</th>\n",
              "      <th>strikerate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2008</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>37.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>123.809512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2008</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>17.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>79</td>\n",
              "      <td>18.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>123.529398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2008</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>36.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2008</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>82</td>\n",
              "      <td>13.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>90.909095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>2008</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>12.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>26.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>58.333368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21610</th>\n",
              "      <td>22357</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>-50.000750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21611</th>\n",
              "      <td>22358</td>\n",
              "      <td>2023</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>13</td>\n",
              "      <td>2.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>-50.000750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21612</th>\n",
              "      <td>22359</td>\n",
              "      <td>2023</td>\n",
              "      <td>7</td>\n",
              "      <td>13</td>\n",
              "      <td>36</td>\n",
              "      <td>2.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>12.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>-50.000750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21613</th>\n",
              "      <td>22360</td>\n",
              "      <td>2023</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>20.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>-50.000750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21614</th>\n",
              "      <td>22361</td>\n",
              "      <td>2023</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>1.0</td>\n",
              "      <td>644</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>16.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>60.00054</td>\n",
              "      <td>-50.000750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20939 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-422a4e33-61c8-4003-9270-98954e98cf01')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-422a4e33-61c8-4003-9270-98954e98cf01 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-422a4e33-61c8-4003-9270-98954e98cf01');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cbeb7b0a-def3-4271-abe9-1ee2196d4552\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cbeb7b0a-def3-4271-abe9-1ee2196d4552')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cbeb7b0a-def3-4271-abe9-1ee2196d4552 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_96b72e6c-2c61-4aa4-81ca-1fb262fdd632\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_FP')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_96b72e6c-2c61-4aa4-81ca-1fb262fdd632 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_FP');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_FP"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_FP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzKflDHVu3J8"
      },
      "outputs": [],
      "source": [
        "# To train the autogluon\n",
        "x_train=df_FP.drop('Total_FP',axis=1)\n",
        "y_train= pd.DataFrame()\n",
        "y_train['Captain/Vice Captain']=df_C['Captain/Vice Captain']\n",
        "y_train['Total_FP']=df_FP['Total_FP']\n",
        "x_test= df_FPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q19GZaAtt7_j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "c9c8d0cd-ff06-40e0-a881-70b0b844dcb8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-781f3bbf1327>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To train custom models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_FP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total_FP'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Captain/Vice Captain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_FP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Total_FP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ],
      "source": [
        "# To train custom models\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(df_FP.drop('Total_FP',axis=1),pd.concat([df_C['Captain/Vice Captain'], df_FP['Total_FP']],axis=1), test_size=0.35, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-_9JJ4ARY0z"
      },
      "outputs": [],
      "source": [
        "x_train2=x_train1.drop([\"home_team\",\"batting_team_bat\",\"bowling_team_bowl\",\"away_team\",\"venue\",\"Player_name\"],axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6geAOh3rAJl"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O4CFvMfSttP"
      },
      "outputs": [],
      "source": [
        "x_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XotQjR-YT8qT"
      },
      "outputs": [],
      "source": [
        "x_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0cJ-ff_Mu24",
        "outputId": "314f114e-424e-40d3-b7c6-9890b3849ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 100)               1400      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 30)                1530      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 30)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 15)                465       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 15)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8461 (33.05 KB)\n",
            "Trainable params: 8461 (33.05 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/35\n",
            "1089/1089 [==============================] - 13s 5ms/step - loss: 1239.3888 - val_loss: 992.3953\n",
            "Epoch 2/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1139.9253 - val_loss: 983.0621\n",
            "Epoch 3/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1106.8879 - val_loss: 986.1639\n",
            "Epoch 4/35\n",
            "1089/1089 [==============================] - 6s 5ms/step - loss: 1084.5355 - val_loss: 991.6887\n",
            "Epoch 5/35\n",
            "1089/1089 [==============================] - 5s 5ms/step - loss: 1069.6080 - val_loss: 983.8820\n",
            "Epoch 6/35\n",
            "1089/1089 [==============================] - 8s 8ms/step - loss: 1057.3875 - val_loss: 988.2466\n",
            "Epoch 7/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1051.2264 - val_loss: 985.6845\n",
            "Epoch 8/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1041.4891 - val_loss: 996.2491\n",
            "Epoch 9/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1040.7723 - val_loss: 986.5808\n",
            "Epoch 10/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1033.7689 - val_loss: 985.4756\n",
            "Epoch 11/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1027.3073 - val_loss: 984.7057\n",
            "Epoch 12/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1032.4319 - val_loss: 985.7056\n",
            "Epoch 13/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1027.9890 - val_loss: 983.3967\n",
            "Epoch 14/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1023.0571 - val_loss: 987.8457\n",
            "Epoch 15/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1023.7909 - val_loss: 991.1903\n",
            "Epoch 16/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1020.3220 - val_loss: 988.2509\n",
            "Epoch 17/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1017.1453 - val_loss: 987.0578\n",
            "Epoch 18/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1015.4632 - val_loss: 982.4745\n",
            "Epoch 19/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1018.2169 - val_loss: 981.8041\n",
            "Epoch 20/35\n",
            "1089/1089 [==============================] - 6s 5ms/step - loss: 1016.7181 - val_loss: 987.1453\n",
            "Epoch 21/35\n",
            "1089/1089 [==============================] - 6s 5ms/step - loss: 1014.5544 - val_loss: 983.6641\n",
            "Epoch 22/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1015.1155 - val_loss: 984.7366\n",
            "Epoch 23/35\n",
            "1089/1089 [==============================] - 5s 5ms/step - loss: 1014.8031 - val_loss: 985.8329\n",
            "Epoch 24/35\n",
            "1089/1089 [==============================] - 5s 5ms/step - loss: 1015.3883 - val_loss: 983.8284\n",
            "Epoch 25/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1014.0413 - val_loss: 984.6374\n",
            "Epoch 26/35\n",
            "1089/1089 [==============================] - 5s 5ms/step - loss: 1017.2286 - val_loss: 986.4697\n",
            "Epoch 27/35\n",
            "1089/1089 [==============================] - 6s 5ms/step - loss: 1015.2069 - val_loss: 982.9379\n",
            "Epoch 28/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1014.5161 - val_loss: 985.3892\n",
            "Epoch 29/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1014.1858 - val_loss: 985.3712\n",
            "Epoch 30/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1014.6006 - val_loss: 989.5284\n",
            "Epoch 31/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1015.6721 - val_loss: 987.2922\n",
            "Epoch 32/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1011.7473 - val_loss: 984.9722\n",
            "Epoch 33/35\n",
            "1089/1089 [==============================] - 4s 4ms/step - loss: 1013.6812 - val_loss: 985.4435\n",
            "Epoch 34/35\n",
            "1089/1089 [==============================] - 5s 4ms/step - loss: 1012.8848 - val_loss: 985.1596\n",
            "Epoch 35/35\n",
            "1089/1089 [==============================] - 6s 6ms/step - loss: 1012.6896 - val_loss: 985.8475\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ab9103cd1e0>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Train the FFNN model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "seed = 61\n",
        "tf.random.set_seed(seed)\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer with 13  neurons\n",
        "model.add(Dense(100, input_dim=13, activation='relu'))\n",
        "\n",
        "# Hidden layer 1\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Hidden layer 2\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Hidden layer 3\n",
        "model.add(Dense(15, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with 1 neuron\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "# Compile the model with the specified optimizer and loss function\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "\n",
        "# Normalize the data\n",
        "scaler_X = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler_X.fit_transform(x_train2.drop('match_id',axis=1))\n",
        "# Train the model\n",
        "model.fit(X_scaled, y_train1[\"Total_FP\"], epochs=35, batch_size=10, validation_split=0.2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U14r7ixks6zW"
      },
      "outputs": [],
      "source": [
        "x_test.fillna(x_test['prev_Total_FP'].mean(),inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VAyLzV8Dsq5r",
        "outputId": "f7314a55-f8f4-40c7-e2d4-51ec4c023430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([36.836514, 36.83697 , 36.837612, 36.837753, 36.837963, 36.837975,\n",
              "       36.838043, 36.83822 , 36.838234, 36.8388  , 36.83968 , 36.83987 ,\n",
              "       36.84057 , 36.840885, 36.841187, 36.841965, 36.845158, 36.84585 ,\n",
              "       36.84752 , 36.856483, 36.85721 , 36.858273, 36.863953, 36.8658  ,\n",
              "       36.868237, 36.868843, 36.869194, 36.86935 , 36.86953 , 36.8707  ,\n",
              "       36.872765, 36.877262, 36.877956, 36.878525, 36.878857, 36.883244,\n",
              "       36.884636, 36.8937  , 36.894344, 36.894707, 36.894955, 36.899654,\n",
              "       36.9022  , 36.905457, 36.90658 , 36.9094  , 36.916763, 36.918304,\n",
              "       36.920185, 36.922493, 36.92345 , 36.924416, 36.92672 , 36.927113,\n",
              "       36.93384 , 36.93594 , 36.942654, 36.943134, 36.94325 , 36.946003,\n",
              "       36.946476, 36.948555, 36.949963, 36.953716, 36.95538 , 36.958668,\n",
              "       36.960503, 36.96704 , 36.968098, 36.96836 , 36.972725, 36.97659 ,\n",
              "       36.986996, 36.991455, 37.000275, 37.019005, 37.0192  , 37.037167,\n",
              "       37.078835, 37.09443 , 37.107494, 37.128086, 37.140358, 37.14206 ,\n",
              "       37.151917, 37.189396, 37.224808, 37.227974, 37.26776 , 37.33458 ,\n",
              "       37.347466, 37.40151 , 37.454216, 37.46745 , 37.475784, 37.554302,\n",
              "       37.555264, 37.5561  , 37.55861 , 37.569515, 37.582832, 37.588936,\n",
              "       37.602283, 37.602467, 37.609642, 37.647537, 37.647583, 37.649506,\n",
              "       37.65126 , 37.65671 , 37.674076, 37.674164, 37.687843, 37.69373 ,\n",
              "       37.696815, 37.70173 , 37.70648 , 37.707607, 37.7121  , 37.71312 ,\n",
              "       37.71471 , 37.715   , 37.729996, 37.735146, 37.747234, 37.749527,\n",
              "       37.760956, 37.780807, 37.782215, 37.785595, 37.805565, 37.807274,\n",
              "       37.822514, 37.83094 , 37.87679 , 37.882236, 37.88257 , 37.88562 ,\n",
              "       37.889217, 37.893547, 37.893772, 37.90178 , 37.90399 , 37.91217 ,\n",
              "       37.927624, 37.93758 , 37.95291 , 37.953556, 37.957394, 37.9705  ,\n",
              "       37.98152 , 37.98258 , 37.992855, 38.012337, 38.014248, 38.0183  ,\n",
              "       38.041092, 38.04155 , 38.057083, 38.06054 , 38.07806 , 38.086063,\n",
              "       38.095104, 38.11007 , 38.117653, 38.14041 , 38.15149 , 38.163483,\n",
              "       38.182777, 38.19948 , 38.201527, 38.206352, 38.208725, 38.218178,\n",
              "       38.22966 , 38.24303 , 38.24312 , 38.245544, 38.25065 , 38.265972,\n",
              "       38.273624, 38.282707, 38.28386 , 38.285492, 38.29364 , 38.298027,\n",
              "       38.300434, 38.308483, 38.329624, 38.339096, 38.350643, 38.3561  ,\n",
              "       38.3571  , 38.386322, 38.389824, 38.397343, 38.398254, 38.42945 ,\n",
              "       38.44866 , 38.449318, 38.46532 , 38.46743 , 38.473373, 38.47524 ,\n",
              "       38.48146 , 38.50132 , 38.54741 , 38.550156, 38.558655, 38.575832,\n",
              "       38.57617 , 38.576626, 38.577244, 38.586685, 38.59338 , 38.595974,\n",
              "       38.62459 , 38.628803, 38.6502  , 38.65117 , 38.657143, 38.663715,\n",
              "       38.7034  , 38.726097, 38.738327, 38.752823, 38.75471 , 38.770218,\n",
              "       38.782684, 38.81134 , 38.829437, 38.83178 , 38.835094, 38.8378  ,\n",
              "       38.839367, 38.84889 , 38.872196, 38.877224, 38.89856 , 38.90448 ,\n",
              "       38.921772, 38.939697, 38.94135 , 38.94463 , 38.95474 , 38.963745,\n",
              "       38.97207 , 38.97269 , 38.978428, 38.981865, 39.005978, 39.007317,\n",
              "       39.01973 , 39.03373 , 39.0358  , 39.042908, 39.044178, 39.058357,\n",
              "       39.08491 , 39.0982  , 39.102924, 39.127743, 39.159534, 39.203037,\n",
              "       39.22528 , 39.229813, 39.232758, 39.235023, 39.247387, 39.25152 ,\n",
              "       39.283756, 39.287872, 39.341923, 39.349487, 39.358887, 39.378098,\n",
              "       39.398537, 39.43598 , 39.438488, 39.451008, 39.48448 , 39.518097,\n",
              "       39.558426, 39.613094, 39.61719 , 39.61948 , 39.63566 , 39.654922,\n",
              "       39.656807, 39.66127 , 39.713066, 39.724667, 39.733253, 39.7404  ,\n",
              "       39.742443, 39.77884 , 39.784523, 39.839375, 39.85803 , 39.858543,\n",
              "       39.858944, 39.917   , 39.94625 , 39.962425, 39.980804, 39.982986,\n",
              "       39.984493, 39.985565, 40.0016  , 40.03399 , 40.13139 , 40.25725 ,\n",
              "       40.270203, 40.29002 , 40.38623 , 40.449066, 40.685005, 40.952347,\n",
              "       40.97289 , 41.00705 , 41.558945, 41.70333 , 41.974617, 42.00261 ,\n",
              "       58.189262, 58.25418 , 58.43536 , 58.452587, 58.460854, 58.645348,\n",
              "       58.79208 , 58.84375 , 58.86863 , 59.00646 , 59.065937, 59.186775,\n",
              "       59.211216, 59.45433 , 59.50898 , 59.58814 , 59.824955, 59.856087,\n",
              "       59.900803, 59.973015, 60.121223, 60.185886, 60.42993 , 60.464863,\n",
              "       60.668777, 60.67916 , 60.73486 , 60.80425 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "y_pred_FP= model.predict(scaler_X.transform(x_test.drop(['match_id',\"home_team\",\"batting_team_bat\",\"bowling_team_bowl\",\"away_team\",\"venue\",\"Player_name\"],axis=1)))\n",
        "np.unique(y_pred_FP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkDGiCxivEzY",
        "outputId": "00e8096d-bf01-4396-9adf-14d82b3d9b90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[58.460854],\n",
              "       [36.836514],\n",
              "       [37.782215],\n",
              "       [37.569515],\n",
              "       [36.836514],\n",
              "       [60.668777],\n",
              "       [36.841187],\n",
              "       [36.836514],\n",
              "       [37.83094 ],\n",
              "       [40.97289 ],\n",
              "       [36.836514],\n",
              "       [58.43536 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [41.558945],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.46745 ],\n",
              "       [36.837975],\n",
              "       [36.96704 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.569515],\n",
              "       [40.685005],\n",
              "       [39.7404  ],\n",
              "       [37.140358],\n",
              "       [38.84889 ],\n",
              "       [36.927113],\n",
              "       [36.943134],\n",
              "       [36.836514],\n",
              "       [37.09443 ],\n",
              "       [38.839367],\n",
              "       [38.75471 ],\n",
              "       [58.25418 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.59338 ],\n",
              "       [38.921772],\n",
              "       [36.836514],\n",
              "       [39.349487],\n",
              "       [36.836514],\n",
              "       [38.657143],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [40.952347],\n",
              "       [39.784523],\n",
              "       [59.973015],\n",
              "       [36.93384 ],\n",
              "       [36.836514],\n",
              "       [39.984493],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.15149 ],\n",
              "       [60.464863],\n",
              "       [36.836514],\n",
              "       [36.991455],\n",
              "       [38.397343],\n",
              "       [39.713066],\n",
              "       [39.398537],\n",
              "       [36.922493],\n",
              "       [59.065937],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.08491 ],\n",
              "       [36.836514],\n",
              "       [37.95291 ],\n",
              "       [38.206352],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.85721 ],\n",
              "       [37.569515],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.986996],\n",
              "       [39.378098],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.968098],\n",
              "       [36.84752 ],\n",
              "       [37.227974],\n",
              "       [36.836514],\n",
              "       [36.894344],\n",
              "       [39.982986],\n",
              "       [37.55861 ],\n",
              "       [36.836514],\n",
              "       [60.185886],\n",
              "       [39.229813],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.90399 ],\n",
              "       [37.128086],\n",
              "       [36.836514],\n",
              "       [39.43598 ],\n",
              "       [38.42945 ],\n",
              "       [39.438488],\n",
              "       [36.836514],\n",
              "       [37.569515],\n",
              "       [38.117653],\n",
              "       [37.893772],\n",
              "       [36.836514],\n",
              "       [38.97269 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.918304],\n",
              "       [38.04155 ],\n",
              "       [36.836514],\n",
              "       [37.602283],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.037167],\n",
              "       [36.836514],\n",
              "       [37.475784],\n",
              "       [36.836514],\n",
              "       [36.868843],\n",
              "       [38.575832],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.81134 ],\n",
              "       [39.247387],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.613094],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.339096],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.298027],\n",
              "       [36.836514],\n",
              "       [38.06054 ],\n",
              "       [38.94135 ],\n",
              "       [37.687843],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.558426],\n",
              "       [39.63566 ],\n",
              "       [36.836514],\n",
              "       [37.88562 ],\n",
              "       [37.87679 ],\n",
              "       [37.992855],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.899654],\n",
              "       [36.836514],\n",
              "       [40.13139 ],\n",
              "       [36.836514],\n",
              "       [38.978428],\n",
              "       [36.837612],\n",
              "       [60.121223],\n",
              "       [39.61719 ],\n",
              "       [36.972725],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.837963],\n",
              "       [36.836514],\n",
              "       [38.558655],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.3561  ],\n",
              "       [37.569515],\n",
              "       [38.550156],\n",
              "       [59.856087],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.878857],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [59.45433 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.0192  ],\n",
              "       [36.836514],\n",
              "       [36.90658 ],\n",
              "       [39.287872],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [40.29002 ],\n",
              "       [37.674076],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.647583],\n",
              "       [38.086063],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.835094],\n",
              "       [38.738327],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.894707],\n",
              "       [38.770218],\n",
              "       [38.7034  ],\n",
              "       [36.97659 ],\n",
              "       [37.609642],\n",
              "       [58.79208 ],\n",
              "       [36.836514],\n",
              "       [59.186775],\n",
              "       [38.19948 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.29364 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.869194],\n",
              "       [36.836514],\n",
              "       [38.245544],\n",
              "       [37.822514],\n",
              "       [60.73486 ],\n",
              "       [36.960503],\n",
              "       [36.836514],\n",
              "       [39.102924],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.61948 ],\n",
              "       [36.836514],\n",
              "       [38.012337],\n",
              "       [36.836514],\n",
              "       [39.94625 ],\n",
              "       [37.889217],\n",
              "       [36.953716],\n",
              "       [36.84057 ],\n",
              "       [60.80425 ],\n",
              "       [36.838234],\n",
              "       [36.958668],\n",
              "       [36.884636],\n",
              "       [36.836514],\n",
              "       [39.044178],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.019005],\n",
              "       [37.735146],\n",
              "       [39.042908],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.749527],\n",
              "       [36.836514],\n",
              "       [37.555264],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.83987 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.70648 ],\n",
              "       [36.894955],\n",
              "       [37.569515],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [60.42993 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.6502  ],\n",
              "       [58.189262],\n",
              "       [36.9094  ],\n",
              "       [39.235023],\n",
              "       [38.201527],\n",
              "       [39.005978],\n",
              "       [36.946476],\n",
              "       [36.836514],\n",
              "       [37.98152 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [59.58814 ],\n",
              "       [36.836514],\n",
              "       [37.9705  ],\n",
              "       [37.151917],\n",
              "       [36.836514],\n",
              "       [38.83178 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.715   ],\n",
              "       [38.25065 ],\n",
              "       [36.836514],\n",
              "       [39.159534],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.917   ],\n",
              "       [36.836514],\n",
              "       [36.92345 ],\n",
              "       [37.696815],\n",
              "       [38.46532 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.96836 ],\n",
              "       [36.872765],\n",
              "       [36.836514],\n",
              "       [38.282707],\n",
              "       [39.358887],\n",
              "       [36.863953],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.939697],\n",
              "       [40.270203],\n",
              "       [39.85803 ],\n",
              "       [38.473373],\n",
              "       [36.840885],\n",
              "       [37.90178 ],\n",
              "       [36.836514],\n",
              "       [37.569515],\n",
              "       [36.836514],\n",
              "       [38.273624],\n",
              "       [36.877956],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.663715],\n",
              "       [37.953556],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.518097],\n",
              "       [39.980804],\n",
              "       [38.8378  ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.88257 ],\n",
              "       [37.807274],\n",
              "       [38.981865],\n",
              "       [36.837753],\n",
              "       [38.057083],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.3571  ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [41.974617],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.01973 ],\n",
              "       [58.645348],\n",
              "       [39.341923],\n",
              "       [38.46743 ],\n",
              "       [38.300434],\n",
              "       [37.554302],\n",
              "       [36.836514],\n",
              "       [36.838043],\n",
              "       [60.67916 ],\n",
              "       [37.70173 ],\n",
              "       [36.95538 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.014248],\n",
              "       [38.62459 ],\n",
              "       [36.836514],\n",
              "       [37.347466],\n",
              "       [36.836514],\n",
              "       [37.927624],\n",
              "       [38.94463 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.386322],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.14206 ],\n",
              "       [36.836514],\n",
              "       [38.28386 ],\n",
              "       [37.98258 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.22528 ],\n",
              "       [37.93758 ],\n",
              "       [36.836514],\n",
              "       [38.265972],\n",
              "       [36.836514],\n",
              "       [39.058357],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.780807],\n",
              "       [36.948555],\n",
              "       [38.595974],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.920185],\n",
              "       [39.203037],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.858273],\n",
              "       [39.858944],\n",
              "       [36.836514],\n",
              "       [41.00705 ],\n",
              "       [40.03399 ],\n",
              "       [36.836514],\n",
              "       [37.65126 ],\n",
              "       [36.836514],\n",
              "       [38.07806 ],\n",
              "       [39.03373 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.9022  ],\n",
              "       [37.569515],\n",
              "       [38.389824],\n",
              "       [36.836514],\n",
              "       [36.916763],\n",
              "       [36.836514],\n",
              "       [59.00646 ],\n",
              "       [36.836514],\n",
              "       [39.127743],\n",
              "       [36.924416],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.84585 ],\n",
              "       [36.83968 ],\n",
              "       [38.11007 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.22966 ],\n",
              "       [36.836514],\n",
              "       [38.54741 ],\n",
              "       [39.0358  ],\n",
              "       [42.00261 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.208725],\n",
              "       [36.877262],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.8707  ],\n",
              "       [36.836514],\n",
              "       [36.8388  ],\n",
              "       [37.000275],\n",
              "       [38.44866 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [41.70333 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.8937  ],\n",
              "       [38.350643],\n",
              "       [38.48146 ],\n",
              "       [36.93594 ],\n",
              "       [39.654922],\n",
              "       [36.8658  ],\n",
              "       [36.836514],\n",
              "       [39.839375],\n",
              "       [39.962425],\n",
              "       [37.602467],\n",
              "       [36.949963],\n",
              "       [38.829437],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.25152 ],\n",
              "       [36.86953 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.647537],\n",
              "       [39.656807],\n",
              "       [36.836514],\n",
              "       [38.449318],\n",
              "       [37.71471 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.726097],\n",
              "       [36.836514],\n",
              "       [37.107494],\n",
              "       [37.078835],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.963745],\n",
              "       [38.398254],\n",
              "       [39.733253],\n",
              "       [37.40151 ],\n",
              "       [36.836514],\n",
              "       [38.872196],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.454216],\n",
              "       [37.224808],\n",
              "       [36.836514],\n",
              "       [38.95474 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.329624],\n",
              "       [36.836514],\n",
              "       [59.211216],\n",
              "       [36.836514],\n",
              "       [37.7121  ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.90448 ],\n",
              "       [39.724667],\n",
              "       [36.836514],\n",
              "       [37.649506],\n",
              "       [36.836514],\n",
              "       [37.582832],\n",
              "       [36.836514],\n",
              "       [39.66127 ],\n",
              "       [38.628803],\n",
              "       [36.836514],\n",
              "       [37.33458 ],\n",
              "       [59.900803],\n",
              "       [36.86935 ],\n",
              "       [39.007317],\n",
              "       [38.65117 ],\n",
              "       [36.942654],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [39.48448 ],\n",
              "       [38.041092],\n",
              "       [40.25725 ],\n",
              "       [58.86863 ],\n",
              "       [37.569515],\n",
              "       [40.38623 ],\n",
              "       [36.92672 ],\n",
              "       [37.71312 ],\n",
              "       [38.24312 ],\n",
              "       [39.451008],\n",
              "       [36.845158],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.877224],\n",
              "       [36.836514],\n",
              "       [38.163483],\n",
              "       [38.095104],\n",
              "       [38.14041 ],\n",
              "       [38.24303 ],\n",
              "       [39.0982  ],\n",
              "       [38.57617 ],\n",
              "       [36.836514],\n",
              "       [38.586685],\n",
              "       [36.836514],\n",
              "       [37.707607],\n",
              "       [36.836514],\n",
              "       [38.218178],\n",
              "       [36.868237],\n",
              "       [38.285492],\n",
              "       [36.836514],\n",
              "       [37.189396],\n",
              "       [36.836514],\n",
              "       [37.569515],\n",
              "       [37.69373 ],\n",
              "       [58.84375 ],\n",
              "       [36.878525],\n",
              "       [36.836514],\n",
              "       [38.752823],\n",
              "       [36.836514],\n",
              "       [37.805565],\n",
              "       [37.91217 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.957394],\n",
              "       [39.742443],\n",
              "       [36.836514],\n",
              "       [58.452587],\n",
              "       [36.83822 ],\n",
              "       [36.836514],\n",
              "       [37.893547],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.0183  ],\n",
              "       [37.729996],\n",
              "       [39.232758],\n",
              "       [37.5561  ],\n",
              "       [38.97207 ],\n",
              "       [39.283756],\n",
              "       [38.182777],\n",
              "       [37.747234],\n",
              "       [36.94325 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.26776 ],\n",
              "       [40.449066],\n",
              "       [38.308483],\n",
              "       [36.836514],\n",
              "       [37.569515],\n",
              "       [36.836514],\n",
              "       [39.77884 ],\n",
              "       [38.50132 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.577244],\n",
              "       [36.836514],\n",
              "       [39.858543],\n",
              "       [59.824955],\n",
              "       [36.836514],\n",
              "       [37.882236],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [38.782684],\n",
              "       [38.89856 ],\n",
              "       [36.836514],\n",
              "       [36.905457],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.883244],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.760956],\n",
              "       [38.576626],\n",
              "       [37.674164],\n",
              "       [39.985565],\n",
              "       [36.836514],\n",
              "       [59.50898 ],\n",
              "       [36.836514],\n",
              "       [38.47524 ],\n",
              "       [36.83697 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [40.0016  ],\n",
              "       [37.785595],\n",
              "       [36.856483],\n",
              "       [37.65671 ],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.946003],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [37.588936],\n",
              "       [36.836514],\n",
              "       [36.841965],\n",
              "       [36.836514],\n",
              "       [36.836514],\n",
              "       [36.836514]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "y_pred_FP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGW9lTX3ffjd"
      },
      "outputs": [],
      "source": [
        "y_pred= model.predict(scaler_X.transform(x_test1.drop(['match_id',\"home_team\",\"batting_team_bat\",\"bowling_team_bowl\",\"away_team\",\"venue\",\"Player_name\"],axis=1)))\n",
        "rmse = np.sqrt(mean_squared_error(y_test1[\"Total_FP\"], y_pred))\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"Accuracy:\", (y_pred == y_test[\"Captain/Vice Captain\"]).mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emAoDEGM56iV",
        "outputId": "149f502a-81f4-4053-f980-7cd6a537ebcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10.555454, 36.836514, 36.83652 , ..., 42.819855, 42.87734 ,\n",
              "       43.61972 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        " np.unique(y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLtFEmNAvTDR"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler,ADASYN\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.ensemble import BalancedBaggingClassifier\n",
        "from sklearn.svm import OneClassSVM\n",
        "from imblearn.combine import SMOTETomek, SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRNawxJxvTYc"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "X_resampled, y_resampled = smote.fit_resample(x_train1,y_train1['Captain/Vice Captain'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h66rMUXcHgPT",
        "outputId": "20d0059b-db49-4119-8eb0-f8f63e457210"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Captain/Vice Captain\n",
              "1    12582\n",
              "2    12582\n",
              "0    12582\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "y_resampled.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhSJ-LYwwyrI",
        "outputId": "055acf7a-8365-45c0-9b41-89265bc027f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.06      0.00      0.01       294\n",
            "           1       0.92      1.00      0.96      6751\n",
            "           2       0.00      0.00      0.00       284\n",
            "\n",
            "    accuracy                           0.92      7329\n",
            "   macro avg       0.33      0.33      0.32      7329\n",
            "weighted avg       0.85      0.92      0.88      7329\n",
            "\n",
            "[[   1  293    0]\n",
            " [  17 6727    7]\n",
            " [   0  284    0]]\n",
            "Accuracy: 91.79969982262246\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.08      0.09      0.08       294\n",
            "           1       0.92      0.92      0.92      6751\n",
            "           2       0.04      0.04      0.04       284\n",
            "\n",
            "    accuracy                           0.86      7329\n",
            "   macro avg       0.35      0.35      0.35      7329\n",
            "weighted avg       0.86      0.86      0.86      7329\n",
            "\n",
            "[[  25  255   14]\n",
            " [ 283 6236  232]\n",
            " [  17  256   11]]\n",
            "Accuracy: 85.57784145176696\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=41,\n",
        "        max_depth=60,\n",
        "        bootstrap=True,\n",
        "        max_features='sqrt',\n",
        "        class_weight='balanced',\n",
        "        criterion='gini',\n",
        "        random_state=40),\n",
        "    \"Decision_tree_classifier\":DecisionTreeClassifier(criterion='gini',\n",
        "                                                      max_depth=8,\n",
        "                                                      max_features=None,\n",
        "                                                      random_state=60)\n",
        "}\n",
        "\n",
        "for clf_name, clf in classifiers.items():\n",
        "    clf.fit(X_resampled.drop('match_id',axis=1), y_resampled)\n",
        "    y_pred_C = clf.predict(x_test.drop('match_id',axis=1))\n",
        "    y_pred = clf.predict(x_test1.drop('match_id',axis=1))\n",
        "\n",
        "    print(classification_report(y_test1['Captain/Vice Captain'], y_pred))\n",
        "    print(confusion_matrix(y_test1['Captain/Vice Captain'], y_pred))\n",
        "    accuracy = accuracy_score(y_test1['Captain/Vice Captain'], y_pred)\n",
        "    print(\"Accuracy:\", accuracy*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBPOJkCk9fzT",
        "outputId": "2b7b6fab-48d2-46b9-de4f-8ab335a840de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 1, 1, 0,\n",
              "       1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 2, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 2, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "y_pred_C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njaAQEc_Cetd",
        "outputId": "dc89caca-9482-4064-a685-ae24b22fe487"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "np.unique(y_pred_C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OllveH2D7dTh",
        "outputId": "f03b6406-b2b2-4220-f687-dc93dae18564"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(709,)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "y_pred_C.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywQcg8ok7tPx"
      },
      "outputs": [],
      "source": [
        "g=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMWUqm7r7JzX",
        "outputId": "b3e65467-2d0e-4170-9aea-5ce91699d299"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'C',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'NC',\n",
              " 'VC',\n",
              " 'NC',\n",
              " 'NC']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "for i in y_pred_C:\n",
        "  if(i==0):\n",
        "    g.append('C')\n",
        "  elif (i==1):\n",
        "    g.append('NC')\n",
        "  else:\n",
        "    g.append('VC')\n",
        "\n",
        "g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HX_M5yDb5niY"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['match_id']= x_test['match_id']\n",
        "submission['Total_FP']=y_pred_FP\n",
        "submission['Captain/Vice Captain']= g\n",
        "\n",
        "submission.to_csv('loserrr-1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcK7aalVVc7i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c156ad2-d61f-450d-d1db-700b71c76a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: autogluon.core[all]==1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (1.1.0)\n",
            "Requirement already satisfied: autogluon.features==1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (1.1.0)\n",
            "Requirement already satisfied: autogluon.tabular[all]==1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (1.1.0)\n",
            "Requirement already satisfied: autogluon.multimodal==1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (1.1.0)\n",
            "Requirement already satisfied: autogluon.timeseries[all]==1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (1.25.2)\n",
            "Requirement already satisfied: scipy<1.13,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (3.3)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (3.7.1)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (1.34.121)\n",
            "Requirement already satisfied: autogluon.common==1.1.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (1.1.0)\n",
            "Requirement already satisfied: ray[default,tune]<2.11,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (2.10.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.0->autogluon) (0.2.7)\n",
            "Requirement already satisfied: Pillow<11,>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (10.0.1)\n",
            "Requirement already satisfied: torch<2.2,>=2.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (2.1.2)\n",
            "Requirement already satisfied: lightning<2.2,>=2.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (2.1.4)\n",
            "Requirement already satisfied: transformers[sentencepiece]<4.39.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (4.38.2)\n",
            "Requirement already satisfied: accelerate<0.22.0,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.21.0)\n",
            "Requirement already satisfied: jsonschema<4.22,>=4.18 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (4.19.2)\n",
            "Requirement already satisfied: seqeval<1.3.0,>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (1.2.2)\n",
            "Requirement already satisfied: evaluate<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.4.2)\n",
            "Requirement already satisfied: timm<0.10.0,>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.9.16)\n",
            "Requirement already satisfied: torchvision<0.17.0,>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.16.2)\n",
            "Requirement already satisfied: scikit-image<0.21.0,>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.19.3)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (1.3)\n",
            "Requirement already satisfied: torchmetrics<1.3.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (1.2.1)\n",
            "Requirement already satisfied: nptyping<2.5.0,>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (2.4.1)\n",
            "Requirement already satisfied: omegaconf<2.3.0,>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (2.2.3)\n",
            "Requirement already satisfied: pytorch-metric-learning<2.4,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (2.3.0)\n",
            "Requirement already satisfied: nlpaug<1.2.0,>=1.1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (1.1.11)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (3.8.1)\n",
            "Requirement already satisfied: openmim<0.4.0,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.3.9)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (3.1.4)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (2.15.2)\n",
            "Requirement already satisfied: pytesseract<0.3.11,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (0.3.10)\n",
            "Requirement already satisfied: nvidia-ml-py3==7.352.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (7.352.0)\n",
            "Requirement already satisfied: pdf2image<1.19,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.0->autogluon) (1.17.0)\n",
            "Requirement already satisfied: xgboost<2.1,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.0->autogluon) (2.0.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.0->autogluon) (2.7.15)\n",
            "Requirement already satisfied: lightgbm<4.4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.0->autogluon) (4.1.0)\n",
            "Requirement already satisfied: catboost<1.3,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.0->autogluon) (1.2.5)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (1.4.2)\n",
            "Requirement already satisfied: pytorch-lightning<2.2,>=2.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (2.1.4)\n",
            "Requirement already satisfied: gluonts<0.14.4,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (0.14.3)\n",
            "Requirement already satisfied: statsforecast<1.5,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: mlforecast<0.10.1,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (0.10.0)\n",
            "Requirement already satisfied: utilsforecast<0.0.11,>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (0.0.10)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (3.10.3)\n",
            "Requirement already satisfied: optimum[onnxruntime]<1.19,>=1.17 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries[all]==1.1.0->autogluon) (1.18.1)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.0->autogluon.core[all]==1.1.0->autogluon) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.0->autogluon.core[all]==1.1.0->autogluon) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.0->autogluon) (24.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.0->autogluon) (6.0.1)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.121 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==1.1.0->autogluon) (1.34.121)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==1.1.0->autogluon) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core[all]==1.1.0->autogluon) (0.10.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon) (0.8.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon) (1.16.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (2.19.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.23.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (23.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.5.43)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.0.3)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (3.7.4)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14.4,>=0.14.0->autogluon.timeseries[all]==1.1.0->autogluon) (2.7.3)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14.4,>=0.14.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts<0.14.4,>=0.14.0->autogluon.timeseries[all]==1.1.0->autogluon) (4.12.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.0->autogluon) (0.18.3)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.0->autogluon) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.0->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.0->autogluon) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.0->autogluon) (0.18.1)\n",
            "Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (0.11.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.58.1)\n",
            "Requirement already satisfied: window-ops in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.0.15)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon) (5.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.0->autogluon) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.0->autogluon) (2024.5.15)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.0->autogluon) (4.9.3)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.4.6)\n",
            "Requirement already satisfied: model-index in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.1.11)\n",
            "Requirement already satisfied: opendatalab in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.0.10)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (13.7.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.9.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (1.12.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (1.16.1)\n",
            "Requirement already satisfied: onnxruntime>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (1.18.0)\n",
            "Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (3.20.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core[all]==1.1.0->autogluon) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core[all]==1.1.0->autogluon) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core[all]==1.1.0->autogluon) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (3.14.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (1.0.8)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (1.4.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (2.6.2.2)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (14.0.2)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (3.9.5)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.3.14)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.20.0)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (6.4.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (20.26.2)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (1.64.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.1.0->autogluon) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.1.0->autogluon) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.1.0->autogluon) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.1.0->autogluon) (2024.6.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon) (2024.5.22)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.0->autogluon) (1.6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core[all]==1.1.0->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.14.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (1.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (3.0.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.0->autogluon) (0.4.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.2,>=2.1->autogluon.multimodal==1.1.0->autogluon) (12.5.40)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.39.0,>=4.38.0->autogluon.multimodal==1.1.0->autogluon) (0.15.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.39.0,>=4.38.0->autogluon.multimodal==1.1.0->autogluon) (0.1.99)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.1.0->autogluon) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.1.0->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.1.0->autogluon) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.1.0->autogluon) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core[all]==1.1.0->autogluon) (3.1.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (4.0.3)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.0->autogluon) (0.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon) (4.12.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.41.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (24.3.25)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts<0.14.4,>=0.14.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts<0.14.4,>=0.14.0->autogluon.timeseries[all]==1.1.0->autogluon) (2.18.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (0.9.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (3.4.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries[all]==1.1.0->autogluon) (0.5.6)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.3.8)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (4.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (10.0)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (4.1.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (2.11.1)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (3.20.0)\n",
            "Requirement already satisfied: openxlab in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.0.11)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.0->autogluon) (8.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum[onnxruntime]<1.19,>=1.17->autogluon.timeseries[all]==1.1.0->autogluon) (1.3.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0->autogluon.core[all]==1.1.0->autogluon) (1.63.1)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.0->autogluon) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<3,>=2.9->autogluon.multimodal==1.1.0->autogluon) (3.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (0.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.0->autogluon) (2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core[all]==1.1.0->autogluon) (1.7.1)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.0->autogluon) (1.1.1)\n",
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.32.3)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.6.2)\n"
          ]
        }
      ],
      "source": [
        "# Adding the autogluon model:\n",
        "!pip install autogluon\n",
        "!pip install --upgrade mxnet\n",
        "from autogluon.tabular import TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model using AutoGluon\n",
        "predictor = TabularPredictor(label=\"Captain/Vice Captain\").fit(\n",
        "    df_C,\n",
        "    presets=\"high_quality\",\n",
        "    ag_args_fit={\"num_gpus\": 1},\n",
        "    ag_args_ensemble=dict(fold_fitting_strategy=\"sequential_local\")\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMDLQ9ogVytP",
        "outputId": "bade0e73-dfba-4c87-a0e5-f5fda78926b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240604_132213\"\n",
            "Presets specified: ['high_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "Dynamic stacking is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "Detecting stacked overfitting by sub-fitting AutoGluon on the input data. That is, copies of AutoGluon will be sub-fit on subset(s) of the data. Then, the holdout validation data is used to detect stacked overfitting.\n",
            "Sub-fit(s) time limit is: 3600 seconds.\n",
            "Starting holdout-based sub-fit for dynamic stacking. Context path is: AutogluonModels/ag-20240604_132213/ds_sub_fit/sub_fit_ho.\n",
            "Running the sub-fit in a ray process to avoid memory leakage.\n",
            "Spend 957 seconds for the sub-fit(s) during dynamic stacking.\n",
            "Time left for full fit of AutoGluon: 2643 seconds.\n",
            "Starting full fit now with num_stack_levels 1.\n",
            "Beginning AutoGluon training ... Time limit = 2643s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240604_132213\"\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.0\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Apr 28 14:29:16 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       9.14 GB / 12.67 GB (72.1%)\n",
            "Disk Space Avail:   44.55 GB / 78.19 GB (57.0%)\n",
            "===================================================\n",
            "Train Data Rows:    20939\n",
            "Train Data Columns: 25\n",
            "Label Column:       Captain/Vice Captain\n",
            "Problem Type:       multiclass\n",
            "Preprocessing data ...\n",
            "Train Data Class Count: 3\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9368.04 MB\n",
            "\tTrain Data (Original)  Memory Usage: 12.70 MB (0.1% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting TextSpecialFeatureGenerator...\n",
            "\t\t\tFitting BinnedFeatureGenerator...\n",
            "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\t\tFitting TextNgramFeatureGenerator...\n",
            "\t\t\tFitting CountVectorizer for text features: ['match_name', 'prev_Overs_Bowled']\n",
            "\t\t\tCountVectorizer fit with vocabulary size = 307\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])        : 13 | ['batting_innings', 'bowling_innings', 'prev_runs', 'prev_balls', 'prev_sixes', ...]\n",
            "\t\t('int', [])          :  4 | ['match_id', 'season', 'prev_duck', 'luck']\n",
            "\t\t('object', [])       :  6 | ['home_team', 'away_team', 'venue', 'Player_name', 'bowling_team_bowl', ...]\n",
            "\t\t('object', ['text']) :  2 | ['match_name', 'prev_Overs_Bowled']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])                    :   6 | ['home_team', 'away_team', 'venue', 'Player_name', 'bowling_team_bowl', ...]\n",
            "\t\t('category', ['text_as_category'])  :   2 | ['match_name', 'prev_Overs_Bowled']\n",
            "\t\t('float', [])                       :  10 | ['prev_runs', 'prev_balls', 'prev_sixes', 'prev_fours', 'prev_wickets', ...]\n",
            "\t\t('int', [])                         :   3 | ['match_id', 'season', 'luck']\n",
            "\t\t('int', ['binned', 'text_special']) :  10 | ['match_name.char_count', 'match_name.capital_ratio', 'match_name.lower_ratio', 'match_name.symbol_ratio. ', 'prev_Overs_Bowled.char_count', ...]\n",
            "\t\t('int', ['bool'])                   :   4 | ['batting_innings', 'bowling_innings', 'prev_Dream Team', 'prev_duck']\n",
            "\t\t('int', ['text_ngram'])             : 307 | ['__nlp__.10', '__nlp__.10 12', '__nlp__.10 12 14', '__nlp__.10 12 15', '__nlp__.10 12 16', ...]\n",
            "\t6.5s = Fit runtime\n",
            "\t25 features in original data used to generate 342 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 14.84 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 6.63s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1757.14s of the 2636.35s of remaining time.\n",
            "\t0.9199\t = Validation score   (accuracy)\n",
            "\t0.17s\t = Training   runtime\n",
            "\t12.62s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1743.86s of the 2623.07s of remaining time.\n",
            "\t0.9186\t = Validation score   (accuracy)\n",
            "\t0.19s\t = Training   runtime\n",
            "\t12.72s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1730.55s of the 2609.76s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "No improvement since epoch 1: early stopping\n",
            "No improvement since epoch 3: early stopping\n",
            "No improvement since epoch 1: early stopping\n",
            "No improvement since epoch 3: early stopping\n",
            "No improvement since epoch 1: early stopping\n",
            "No improvement since epoch 6: early stopping\n",
            "No improvement since epoch 3: early stopping\n",
            "No improvement since epoch 3: early stopping\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t191.46s\t = Training   runtime\n",
            "\t0.57s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1538.42s of the 2417.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t29.23s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1507.77s of the 2386.98s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t41.23s\t = Training   runtime\n",
            "\t0.28s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 1466.04s of the 2345.25s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t19.1s\t = Training   runtime\n",
            "\t8.37s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 1438.12s of the 2317.33s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t17.71s\t = Training   runtime\n",
            "\t3.35s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1416.57s of the 2295.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t25.94s\t = Training   runtime\n",
            "\t0.45s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1389.91s of the 2269.12s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t19.32s\t = Training   runtime\n",
            "\t3.52s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 1366.44s of the 2245.64s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t20.11s\t = Training   runtime\n",
            "\t4.23s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1341.4s of the 2220.62s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t16.7s\t = Training   runtime\n",
            "\t0.35s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1324.1s of the 2203.32s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t104.09s\t = Training   runtime\n",
            "\t0.34s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 1219.58s of the 2098.8s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t64.51s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 1154.68s of the 2033.89s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t25.43s\t = Training   runtime\n",
            "\t0.48s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 1128.55s of the 2007.76s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9235\t = Validation score   (accuracy)\n",
            "\t146.39s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 981.69s of the 1860.9s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t37.39s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 943.76s of the 1822.97s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 3: early stopping\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 6: early stopping\n",
            "No improvement since epoch 1: early stopping\n",
            "No improvement since epoch 6: early stopping\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t201.85s\t = Training   runtime\n",
            "\t0.69s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 741.12s of the 1620.33s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t28.7s\t = Training   runtime\n",
            "\t0.58s\t = Validation runtime\n",
            "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 711.59s of the 1590.8s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t32.61s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L1 ... Training model for up to 678.15s of the 1557.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9234\t = Validation score   (accuracy)\n",
            "\t111.54s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: XGBoost_r33_BAG_L1 ... Training model for up to 566.15s of the 1445.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t34.68s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: ExtraTrees_r42_BAG_L1 ... Training model for up to 530.88s of the 1410.09s of remaining time.\n",
            "\t0.9225\t = Validation score   (accuracy)\n",
            "\t242.95s\t = Training   runtime\n",
            "\t3.76s\t = Validation runtime\n",
            "Fitting model: CatBoost_r137_BAG_L1 ... Training model for up to 283.72s of the 1162.93s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t20.22s\t = Training   runtime\n",
            "\t0.43s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r102_BAG_L1 ... Training model for up to 262.78s of the 1141.99s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "No improvement since epoch 2: early stopping\n",
            "No improvement since epoch 0: early stopping\n",
            "No improvement since epoch 7: early stopping\n",
            "No improvement since epoch 0: early stopping\n",
            "No improvement since epoch 7: early stopping\n",
            "No improvement since epoch 0: early stopping\n",
            "No improvement since epoch 0: early stopping\n",
            "No improvement since epoch 0: early stopping\n",
            "\t0.9234\t = Validation score   (accuracy)\n",
            "\t28.36s\t = Training   runtime\n",
            "\t0.29s\t = Validation runtime\n",
            "Fitting model: CatBoost_r13_BAG_L1 ... Training model for up to 234.0s of the 1113.22s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t31.35s\t = Training   runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Fitting model: RandomForest_r195_BAG_L1 ... Training model for up to 201.92s of the 1081.13s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 249 due to low time. Expected time usage reduced from 243.2s -> 201.9s...\n",
            "\t0.923\t = Validation score   (accuracy)\n",
            "\t230.1s\t = Training   runtime\n",
            "\t3.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 847.31s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 1.0}\n",
            "\t0.9235\t = Validation score   (accuracy)\n",
            "\t2.31s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting 108 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 844.96s of the 844.76s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 2: early stopping\n",
            "No improvement since epoch 1: early stopping\n",
            "No improvement since epoch 2: early stopping\n",
            "No improvement since epoch 3: early stopping\n",
            "No improvement since epoch 4: early stopping\n",
            "No improvement since epoch 5: early stopping\n",
            "\t0.9225\t = Validation score   (accuracy)\n",
            "\t193.54s\t = Training   runtime\n",
            "\t0.59s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 650.54s of the 650.36s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t80.74s\t = Training   runtime\n",
            "\t0.21s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 569.27s of the 569.07s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\t0.9234\t = Validation score   (accuracy)\n",
            "\t125.18s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 443.24s of the 443.06s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t47.75s\t = Training   runtime\n",
            "\t3.91s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 391.11s of the 390.91s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t35.45s\t = Training   runtime\n",
            "\t3.62s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 351.64s of the 351.44s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "\tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t29.12s\t = Training   runtime\n",
            "\t0.42s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 321.59s of the 321.4s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t22.72s\t = Training   runtime\n",
            "\t4.68s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 293.5s of the 293.3s of remaining time.\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t16.98s\t = Training   runtime\n",
            "\t3.81s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 272.18s of the 271.98s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9234\t = Validation score   (accuracy)\n",
            "\t27.59s\t = Training   runtime\n",
            "\t0.47s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 243.77s of the 243.57s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\t0.9234\t = Validation score   (accuracy)\n",
            "\t132.17s\t = Training   runtime\n",
            "\t1.11s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 110.27s of the 110.08s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with SequentialLocalFoldFittingStrategy\n",
            "\tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 63. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0767762\n",
            "\tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 47. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0767762\n",
            "\tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 51. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0767762\n",
            "\tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 56. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0764234\n",
            "\tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 63. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0764234\n",
            "\tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 71. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0768055\n",
            "\tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 71. Best iteration is:\n",
            "\t[1]\tvalid_set's multi_error: 0.0768055\n",
            "\tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
            "Warning: GPU mode might not be installed for LightGBM, GPU training raised an exception. Falling back to CPU training...Refer to LightGBM GPU documentation: https://github.com/Microsoft/LightGBM/tree/master/python-package#build-gpu-versionOne possible method is:\tpip uninstall lightgbm -y\tpip install lightgbm --install-option=--gpu\n",
            "\tRan out of time, early stopping on iteration 75. Best iteration is:\n",
            "\t[75]\tvalid_set's multi_error: 0.0764234\n",
            "\t0.9233\t = Validation score   (accuracy)\n",
            "\t107.21s\t = Training   runtime\n",
            "\t0.3s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -0.61s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 1.0}\n",
            "\t0.9235\t = Validation score   (accuracy)\n",
            "\t1.52s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2645.19s ... Best model: \"WeightedEnsemble_L2\"\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.17s\t = Training   runtime\n",
            "\t12.62s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.19s\t = Training   runtime\n",
            "\t12.72s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 3.\n",
            "\t3.69s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t0.64s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t0.99s\t = Training   runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t19.1s\t = Training   runtime\n",
            "\t8.37s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t17.71s\t = Training   runtime\n",
            "\t3.35s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\t0.86s\t = Training   runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t19.32s\t = Training   runtime\n",
            "\t3.52s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t20.11s\t = Training   runtime\n",
            "\t4.23s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\t0.91s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
            "\t14.66s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
            "\t0.88s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
            "\t0.67s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
            "\t16.19s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
            "\t0.68s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 4.\n",
            "\t9.16s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
            "\t1.21s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_r96_BAG_L1_FULL ...\n",
            "\t0.95s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_r22_BAG_L1_FULL ...\n",
            "\t15.39s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: XGBoost_r33_BAG_L1_FULL ...\n",
            "\t0.77s\t = Training   runtime\n",
            "Fitting model: ExtraTrees_r42_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t242.95s\t = Training   runtime\n",
            "\t3.76s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_r137_BAG_L1_FULL ...\n",
            "\t0.89s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_r102_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 2.\n",
            "\t1.28s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_r13_BAG_L1_FULL ...\n",
            "\t0.76s\t = Training   runtime\n",
            "Fitting model: RandomForest_r195_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t230.1s\t = Training   runtime\n",
            "\t3.02s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 1.0}\n",
            "\t2.31s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L2_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 3.\n",
            "\t4.51s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\t1.18s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\t2.65s\t = Training   runtime\n",
            "Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t47.75s\t = Training   runtime\n",
            "\t3.91s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t35.45s\t = Training   runtime\n",
            "\t3.62s\t = Validation runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\t1.4s\t = Training   runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t22.72s\t = Training   runtime\n",
            "\t4.68s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\t16.98s\t = Training   runtime\n",
            "\t3.81s\t = Validation runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: XGBoost_BAG_L2_FULL ...\n",
            "\t2.76s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: NeuralNetTorch_BAG_L2_FULL ...\n",
            "\t12.67s\t = Training   runtime\n",
            "Fitting 1 L2 models ...\n",
            "Fitting model: LightGBMLarge_BAG_L2_FULL ...\n",
            "\t3.8s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 1.0}\n",
            "\t1.52s\t = Training   runtime\n",
            "Updated best model to \"NeuralNetTorch_r79_BAG_L1_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"NeuralNetTorch_r79_BAG_L1_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 110.12s ... Best model: \"NeuralNetTorch_r79_BAG_L1_FULL\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240604_132213\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Refit complete, total runtime = 156.59s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
        "# TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240602_175553\")\n",
        "predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20240604_132213\")\n",
        "# Make predictions on the test data\n",
        "y_pred = predictor.predict(x_test1.drop('match_id',axis=1))\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (y_pred == df_C[\"Captain/Vice Captain\"]).mean()\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "wPc-aFOWVz0l",
        "outputId": "f9ff198e-1997-43cc-dd9f-e0cdc0768974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: Could not find version file at \"AutogluonModels/ag-20240604_132213/__version__\".\n",
            "This means that the predictor was fit in a version `<=0.3.1`.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'AutogluonModels/ag-20240604_132213/predictor.pkl'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9f1f7d37620b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Refit complete, total runtime = 156.59s ... Best model: \"WeightedEnsemble_L2_FULL\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240602_175553\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AutogluonModels/ag-20240604_132213\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make predictions on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_C\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path, verbosity, require_version_match, require_py_version_match, check_packages)\u001b[0m\n\u001b[1;32m   4234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion_saved\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4236\u001b[0;31m             \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4238\u001b[0m                 \u001b[0mversion_saved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m   4180\u001b[0m         \u001b[0mInner\u001b[0m \u001b[0mload\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mload\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \"\"\"\n\u001b[0;32m-> 4182\u001b[0;31m         \u001b[0mpredictor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTabularPredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m         \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_learner_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m         \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_post_fit_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/common/loaders/load_pkl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, format, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompression_fn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompression_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mcompression_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompression_fn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidated_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcompression_fn_kwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mobject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AutogluonModels/ag-20240604_132213/predictor.pkl'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZpXe_saWD3y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}